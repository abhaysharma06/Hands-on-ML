{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINITION\n",
    "\n",
    "\n",
    "Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Computer Vision is one of the hottest and one of most important application in artificial intelligence. It is making tremendous advances in self-driving cars, robotics as well as in various photo correction app .Computer vision is a part of artificial intelligence where computer can see the world, analyze visual data and make decisions from it about the environment and situation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Every picture tells a story . Goal of computer vision is to write computer programs that can interpret images.So what we are going to do is to take images and whats come out is something meaning of it ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer Vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\n",
    "\n",
    "Sub-domains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, and image restoration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why To Study CV ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manipulation in processing of imagery .\n",
    "Extracting information of imagery .\n",
    "        Building 3d representation.\n",
    "        Motion Capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Colour Spaces ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Color spaces are different types of color modes, used in image processing and signals and system for various purposes. Some of the common color spaces are\n",
    "1.RGB\n",
    "2.HSV\n",
    "3.BGR\n",
    "4.CMYK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt                        \n",
    "#print image\n",
    "img=cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\")\n",
    "plt.imshow(img)                                                     ## opencv stores BGR image by default\n",
    "plt.show()\n",
    "\n",
    "#printing color image of an image\n",
    "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img2)                                                ## original image               ## Convert BGR to RGB image\n",
    "plt.show()\n",
    "#printing hsv image of an image\n",
    "hsv_image = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)                   ## Convert BGR to HSV image \n",
    "plt.imshow(hsv_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE ROTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "image = cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\") \n",
    "rows,cols = image.shape[:2] \n",
    "#(col/2,rows/2) is the center of rotation for the image \n",
    "# M is the cordinates of the center \n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),180,1) \n",
    "dst = cv2.warpAffine(image,M,(cols,rows)) \n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=ask_tracker()\n",
    "tracker_name=str(tracker).split()[0][1:]\n",
    "\n",
    "#read video\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#read first frame\n",
    "ret,frame=cap.read()\n",
    "\n",
    "roi=cv2.selectROI(frame,False)\n",
    "\n",
    "ret=tracker.init(frame,roi)\n",
    "\n",
    "while True:\n",
    "    frame,ret=cap.read()\n",
    "    success,roi=tracker.update(frame)\n",
    "    x,y,w,h=tuple(map(int,roi))\n",
    "    \n",
    "    if success:\n",
    "        p1=x,y\n",
    "        p2=(x+w ,y+h)\n",
    "        cv2.rectangle(frame,p1,p2,(0,255,0),3)\n",
    "    else:\n",
    "        cv2.putText(frame,\"Failure to Detect Tracling\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,1)\n",
    "    cv2.putText(frame,tracker_name,(20,400),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3)    \n",
    "        \n",
    "    cv2.imshow(tracker_name,frame)\n",
    "    k=cv2.waitKey(1) and 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "    cap.release()\n",
    "    cap.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTICAL FLOW CODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movemement of object or camera. It is 2D vector field where each vector is a displacement vector showing the movement of points from first frame to second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\")\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Black and White (gray scale)\n",
    " \n",
    "img = cv2.imread (\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\")\n",
    " \n",
    "cv2.imshow(\"picture\", img) \n",
    " \n",
    "cv2.waitKey(0)\n",
    "\n",
    "# cv2.waitKey(2000)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#There are 2 parameters to the imshow function which is the name of the window and the image object to be displayed.\n",
    "# waitKey makes the window static until the user presses a key\n",
    "#we use destroyAllWindows to close the window based on the waitForKey parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2      # Resize image\n",
    " \n",
    "\n",
    " \n",
    "img = cv2.imread (\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\",1)\n",
    " \n",
    "resized_image = cv2.resize(img, (650,500))\n",
    " \n",
    "cv2.imshow(\"My_image\", resized_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resized_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resized_image = cv2.resize(img, int(img.shape[1]/2), int(img.shape[0]/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2      # Resize image\n",
    " \n",
    "# Black and White (gray scale)\n",
    " \n",
    "img = cv2.imread (\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\",1)\n",
    " \n",
    "resized_image = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    " \n",
    "cv2.imshow(\"My_image\", resized_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[763 153 563 563]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    " \n",
    "# Create a CascadeClassifier Object\n",
    "face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Rajat arya\\\\Desktop\\\\haarcascade_frontalface_default.xml\")\n",
    " \n",
    "# Reading the image as it is\n",
    "img = cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Pictures\\\\Screenshots\\\\me.png\")\n",
    " \n",
    "# Reading the image as gray scale image\n",
    "gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Search the co-ordintes of the image\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor = 1.05,minNeighbors=5)\n",
    "print(faces)\n",
    "for x,y,w,h in faces:\n",
    "    #cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "    img = cv2.rectangle(img, (x,y), (x+w,y+h),(255,20,120),10)\n",
    " \n",
    "resized = cv2.resize(img, (int(img.shape[1]/4),int(img.shape[0]/4)))\n",
    " \n",
    "cv2.imshow(\"Gray\", resized)\n",
    " \n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x+w,y+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt                        \n",
    "#print image\n",
    "img=cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Downloads\\\\index.png\")\n",
    "plt.imshow(img)                                                     ## opencv stores BGR image by default\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img2)                                                ## original image               ## Convert BGR to RGB image\n",
    "plt.show()\n",
    "#printing hsv image of an image\n",
    "hsv_image = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)                   ## Convert BGR to HSV image \n",
    "plt.imshow(hsv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "video = cv2.VideoCapture(0)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "video = cv2.VideoCapture(0)\n",
    "check,frame =video.read()\n",
    "cv2.imshow(\"video\",frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Create a CascadeClassifier Object\n",
    "eye_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Rajat arya\\\\Desktop\\\\haarcascade_eye.xml\")\n",
    " \n",
    "# Reading the image as it is\n",
    "img = cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Pictures\\\\Screenshots\\\\me.png\")\n",
    " \n",
    "# Reading the image as gray scale image\n",
    "gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Search the co-ordintes of the image\n",
    "Eyes = eye_cascade.detectMultiScale(gray_img, scaleFactor = 1.05,minNeighbors=5)\n",
    "#print(faces)\n",
    "for x,y,w,h in Eyes:\n",
    "    #cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "    img = cv2.rectangle(img, (x,y), (x+w,y+h),(255,20,120),10)\n",
    " \n",
    "resized = cv2.resize(img, (int(img.shape[1]/4),int(img.shape[0]/4)))\n",
    " \n",
    "cv2.imshow(\"Gray\", resized)\n",
    " \n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    #modified code for faces and eyes detection\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Rajat arya\\\\Desktop\\\\haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Rajat arya\\\\Desktop\\\\haarcascade_eye.xml\")\n",
    " \n",
    "img = cv2.imread(\"C:\\\\Users\\\\Rajat arya\\\\Pictures\\\\Screenshots\\\\Screenshot (209).png\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),10)\n",
    "     roi_gray = gray[y:y+h, x:x+w]\n",
    "     roi_color = img[y:y+h, x:x+w]\n",
    "     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "     for (ex,ey,ew,eh) in eyes:\n",
    "         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),5)\n",
    "resized = cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "        \n",
    "cv2.imshow(\"image\",resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "video = cv2.VideoCapture(0)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[226 229 213]\n",
      "  [226 229 213]\n",
      "  [231 230 214]\n",
      "  ...\n",
      "  [143 163 157]\n",
      "  [146 166 161]\n",
      "  [153 173 168]]\n",
      "\n",
      " [[226 229 213]\n",
      "  [226 229 213]\n",
      "  [230 229 213]\n",
      "  ...\n",
      "  [144 164 158]\n",
      "  [147 168 162]\n",
      "  [153 173 168]]\n",
      "\n",
      " [[228 228 215]\n",
      "  [228 228 215]\n",
      "  [229 226 215]\n",
      "  ...\n",
      "  [143 165 153]\n",
      "  [151 169 157]\n",
      "  [158 176 164]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[157 148 134]\n",
      "  [161 152 137]\n",
      "  [169 155 136]\n",
      "  ...\n",
      "  [ 61  85  81]\n",
      "  [ 51  76  72]\n",
      "  [ 50  74  71]]\n",
      "\n",
      " [[155 144 135]\n",
      "  [158 148 138]\n",
      "  [161 150 140]\n",
      "  ...\n",
      "  [ 70  84  82]\n",
      "  [ 58  76  76]\n",
      "  [ 57  75  74]]\n",
      "\n",
      " [[155 144 135]\n",
      "  [156 146 136]\n",
      "  [159 149 139]\n",
      "  ...\n",
      "  [ 71  86  83]\n",
      "  [ 58  76  76]\n",
      "  [ 57  75  74]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "video = cv2.VideoCapture(0)\n",
    "check,frame =video.read()   \n",
    "print(check)\n",
    "print(frame)\n",
    "cv2.imshow(\"video\",frame)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#1 Creating a video object \n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "#3 Creating a frame object\n",
    "check,frame =video.read()\n",
    "\n",
    "cv2.imshow(\"video\",frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#2 shutdown \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video =cv2.VideoCapture(0)\n",
    "a=0\n",
    "while True:\n",
    "    a=a+1\n",
    "    check,frame=video.read()\n",
    "    cv2.imshow(\"capturing\",frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
